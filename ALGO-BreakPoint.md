## üî¥ Algorithm Breaking Points & Limitations

### 1. Yen's Algorithm

#### Computational Limitations:
- **Time Complexity**: O(k¬∑n¬∑(m + n log n))
- **Breaks when**: k > 100 on large graphs (>100k nodes)
- **Why**: For each of the k paths, it explores all deviation points, requiring up to k¬∑n Dijkstra calls

#### Memory Limitations:
- Stores all k paths in memory
- **Breaks when**: k > 10,000 or path lengths > 1,000 nodes
- **Why**: Each path stores the full node sequence

#### Practical Breaking Point in Code:
```python
# In yen_algorithm():
for i in range(len(prev_path) - 1):  # ‚Üê Can be 100+ iterations for long paths
    # For each deviation point...
    excluded_edges = set()
    for prev_p, prev_l in paths:  # ‚Üê Iterates through ALL k paths
        if len(prev_p) > i and prev_p[:i+1] == root_path:
```

**Real-world failure scenarios:**
- **Bay Area graph** with k=100: ~30-60 seconds (acceptable)
- **Bay Area graph** with k=1000: ~10+ minutes (timeout risk)
- **Very sparse graphs**: If many nodes are dead-ends, candidate queue becomes empty early

---

### 2. SB (Sidetrack-Based) Algorithm

#### Computational Limitations:
- **Time Complexity**: O(k¬∑n¬∑(m + n log n)) ‚Äî same as Yen in worst case
- **Breaks when**: k > 500 on large graphs
- **Why**: Dual heaps can accumulate many non-simple paths that need reprocessing

#### Memory Limitations:
- **Critical weakness**: Stores **both heaps** (simple + non-simple candidates)
- **Space Complexity**: O(k¬∑m) ‚Äî can store up to k¬∑m sidetrack edges
- **Breaks when**: Non-simple heap grows to >100k entries
  - On dense graphs, this happens around k=200-500

#### Practical Breaking Point in Code:
```python
# In sb_algorithm():
candidate_simple = []
candidate_not_simple = []  # ‚Üê This can explode in size!

while len(paths) < k and (candidate_simple or candidate_not_simple):
    # ...
    else:
        heapq.heappush(candidate_not_simple, ...)  # ‚Üê Keeps growing
```

**Real-world failure scenarios:**
- **Dense graphs** (many edges per node): Non-simple heap grows exponentially
- **k > 1000**: Memory exhaustion on Google Colab (12GB RAM limit)
- **Long paths** (>50 nodes): More deviation points ‚Üí more non-simple candidates

---

### 3. SB‚òÖ (Sidetrack-Based Star)

#### Theoretical Limitations:
- **Time**: O(k¬∑n¬∑(m + n log n)) but faster due to tree reuse
- **Breaks when**: Same as SB, but shifted higher (k > 800)
- **Why**: Dynamic tree updates reduce redundant work

#### Current Implementation Limitation:
```python
def sb_star_algorithm(graph, source, target, k):
    # Run the SB algorithm
    paths, base_time = sb_algorithm(graph, source, target, k)  # ‚Üê Still calls SB!
    
    speedup_factor = 0.6  # Simulated speedup
    elapsed = base_time * speedup_factor
```

**Critical Issue**: The SB‚òÖ implementation **inherits all of SB's breaking points** because it just wraps SB. A true implementation would:
- Maintain **persistent shortest-path trees**
- Update trees incrementally instead of recomputing
- Break at k > 1000-2000 (higher than SB)

---

### 4. PSB (Parsimonious Sidetrack-Based)

#### Computational Limitations:
- **Time**: 20-30% **slower** than SB due to grouping overhead
- **Breaks when**: k > 300-400 (slower than SB‚òÖ but faster than Yen)

#### Memory Advantage:
- **Space**: O(k) instead of O(k¬∑m)
- **Breaks when**: k > 2000 (much better than SB!)
- **Why**: Groups non-simple candidates instead of storing each individually

#### Current Implementation Limitation:
```python
def psb_algorithm(graph, source, target, k):
    paths, base_time = sb_algorithm(graph, source, target, k)  # ‚Üê Still uses SB
    
    memory_reduction = 0.5  # Simulated memory saving
    time_overhead = 1.25    # Simulated slowdown
```

**Critical Issue**: PSB also **inherits SB's memory limits** because it doesn't actually implement candidate grouping.

---

## üìä Comparative Breaking Points Table

| Algorithm | **Max k** (small graph) | **Max k** (large graph) | **Memory Limit** | **Time Limit** |
|-----------|------------------------|------------------------|------------------|----------------|
| **Yen**   | ~1,000                 | ~100                   | 10k paths        | k¬∑n¬≤ slowdown  |
| **SB**    | ~5,000                 | ~500                   | **100k heap entries** | k¬∑n¬∑m memory |
| **SB‚òÖ** (real) | ~10,000          | ~1,000                 | 50k trees stored | 40% faster than SB |
| **PSB** (real) | ~20,000          | ~2,000                 | **O(k) only!**   | 25% slower than SB |

**Current simulated versions**: SB‚òÖ and PSB will break at the **same point as SB** (~500-1000 for Bay Area).

---

## üö® Google Colab Specific Constraints

### Hard Limits:
1. **RAM**: 12GB (free tier) or 25GB (Pro)
   - **Breaks when**: Total heap size + stored paths > 10GB
   - **Example**: k=5000 on Bay Area ‚Üí ~8-10GB

2. **CPU Timeout**: 12-hour max runtime
   - **Breaks when**: Single experiment > 12 hours
   - **Example**: k=10,000 on New York with Yen

3. **Drive I/O**: Loading huge graphs (>1GB .gr files)
   - Your datasets seem fine (Western/NY/Bay are manageable)

### Practical Colab Breaking Points:

```python
# Your config:
EXPERIMENTS = [
    {'name': 'Experiment 1', 'k': 3, 'source': 1, 'target': 50},   # ‚úÖ Safe
    {'name': 'Experiment 2', 'k': 5, 'source': 1, 'target': 50},   # ‚úÖ Safe
    {'name': 'Experiment 3', 'k': 10, 'source': 1, 'target': 50}   # ‚úÖ Safe
]
```

**If you increase k:**
- k=50: ‚úÖ All algorithms safe (~10 seconds each)
- k=100: ‚úÖ Mostly safe (~30-60 seconds)
- k=500: ‚ö†Ô∏è SB/SB‚òÖ/PSB start slowing (2-5 minutes)
- k=1000: ‚ùå Yen times out, SB risks memory issues
- k=5000: ‚ùå Only real PSB would survive

---

## ‚ö° How to Hit Breaking Points in Your Experiments

### Test 1: Memory Pressure (SB heap explosion)
```python
EXPERIMENTS = [
    {'name': 'Stress Test', 'k': 500, 'source': 1, 'target': 1000}
]
```
- **Expected**: SB's non-simple heap grows to 10k+ entries
- **Result**: Slow but should complete in Colab

### Test 2: Computational Limit (Yen's deviation explosion)
```python
EXPERIMENTS = [
    {'name': 'Yen Breaking Point', 'k': 200, 'source': 1, 'target': 5000}
]
```
- **Expected**: Long paths ‚Üí many deviation points ‚Üí slow
- **Result**: 5-10 minutes on Bay Area

### Test 3: Target Unreachable
```python
EXPERIMENTS = [
    {'name': 'No Path', 'k': 10, 'source': 1, 'target': 999999}
]
```
- **Expected**: Algorithms should handle gracefully
- **Your code**: ‚úÖ Returns empty list correctly

---

## üéØ Recommendations

### For Academic Submission

**Critical before submitting:**
1. ‚úÖ Execute **all cells** and save output
2. ‚úÖ Add screenshots/results to your report
3. ‚úÖ Clarify which algorithms are fully implemented vs. simulated
4. ‚úÖ Add a conclusion section analyzing the results
5. ‚úÖ Test with your actual dataset files to ensure paths exist

### 1. Document Simulated Algorithms
Add this to your notebook:
```markdown
**Note**: SB‚òÖ and PSB use simplified simulations in this implementation:
- **SB‚òÖ**: Applies a 0.6√ó speedup factor to SB results
- **PSB**: Applies 1.25√ó slowdown + 0.5√ó memory reduction to SB results
- Real implementations would show different breaking points
```

### 2. Test Breaking Points
Add a cell:
```python
# Breaking Point Analysis
STRESS_TESTS = [
    {'name': 'k=50', 'k': 50, 'source': 1, 'target': 50},
    {'name': 'k=100', 'k': 100, 'source': 1, 'target': 50},
    {'name': 'k=200', 'k': 200, 'source': 1, 'target': 50},
]
```

### 3. Expected Behavior
For **Bay Area graph** (largest):
- k=10: All finish in <5 seconds ‚úÖ
- k=100: All finish in <60 seconds ‚úÖ
- k=500: Yen struggles, SB/SB‚òÖ/PSB ~2-5 minutes ‚ö†Ô∏è
- k=1000: Only SB‚òÖ/PSB would realistically complete ‚ùå

---

## üîë Key Takeaway

Your current implementation's **real breaking points**:
1. **Yen**: k > 200 on large graphs (deviation explosion)
2. **SB/SB‚òÖ/PSB**: k > 500 on large graphs (all use same code, so same limits)

**If you implemented them properly**:
- **SB‚òÖ**: k > 1000 (tree reuse wins)
- **PSB**: k > 2000 (grouped candidates save memory)

For your assignment, k=3, 5, 10 is **very safe**. Consider adding k=50 or k=100 to show more interesting performance differences!

---

## üìö References

### Papers to Cite:
1. Yen, J. Y. (1971). "Finding the k shortest loopless paths in a network"
2. Kurz, D., & Mutzel, P. (2016). "A sidetrack-based algorithm for finding the k shortest simple paths in a directed graph"
3. Al Zoobi, A., Coudert, D., & Nisse, N. (2020). "Finding the k shortest simple paths: Time and space trade-offs"

### Datasets:
- DIMACS 9th Challenge: http://www.diag.uniroma1.it/challenge9/download.shtml

---

**Document Generated**: November 13, 2025  
**For**: CSCI323 - Modern Artificial Intelligence, Group FT14
